{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c9ef53-29ef-489a-9859-e569a096fcbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T17:32:26.328151900Z",
     "start_time": "2023-08-10T17:32:25.465083500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "JAVA_HOME is not set\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m \n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkSession\n\u001B[0;32m----> 3\u001B[0m spark \u001B[38;5;241m=\u001B[39m \u001B[43mSparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuilder\u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaster\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlocal[*]\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappName\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/apps/miniconda/envs/pyspark_env/lib/python3.9/site-packages/pyspark/sql/session.py:477\u001B[0m, in \u001B[0;36mSparkSession.Builder.getOrCreate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    475\u001B[0m     sparkConf\u001B[38;5;241m.\u001B[39mset(key, value)\n\u001B[1;32m    476\u001B[0m \u001B[38;5;66;03m# This SparkContext may be an existing one.\u001B[39;00m\n\u001B[0;32m--> 477\u001B[0m sc \u001B[38;5;241m=\u001B[39m \u001B[43mSparkContext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msparkConf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001B[39;00m\n\u001B[1;32m    479\u001B[0m \u001B[38;5;66;03m# by all sessions.\u001B[39;00m\n\u001B[1;32m    480\u001B[0m session \u001B[38;5;241m=\u001B[39m SparkSession(sc, options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_options)\n",
      "File \u001B[0;32m~/apps/miniconda/envs/pyspark_env/lib/python3.9/site-packages/pyspark/context.py:512\u001B[0m, in \u001B[0;36mSparkContext.getOrCreate\u001B[0;34m(cls, conf)\u001B[0m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    511\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 512\u001B[0m         \u001B[43mSparkContext\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mSparkConf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context\n",
      "File \u001B[0;32m~/apps/miniconda/envs/pyspark_env/lib/python3.9/site-packages/pyspark/context.py:198\u001B[0m, in \u001B[0;36mSparkContext.__init__\u001B[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001B[0m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gateway \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m gateway\u001B[38;5;241m.\u001B[39mgateway_parameters\u001B[38;5;241m.\u001B[39mauth_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    193\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    194\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    195\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is not allowed as it is a security risk.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    196\u001B[0m     )\n\u001B[0;32m--> 198\u001B[0m \u001B[43mSparkContext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ensure_initialized\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgateway\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgateway\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_init(\n\u001B[1;32m    201\u001B[0m         master,\n\u001B[1;32m    202\u001B[0m         appName,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    212\u001B[0m         memory_profiler_cls,\n\u001B[1;32m    213\u001B[0m     )\n",
      "File \u001B[0;32m~/apps/miniconda/envs/pyspark_env/lib/python3.9/site-packages/pyspark/context.py:432\u001B[0m, in \u001B[0;36mSparkContext._ensure_initialized\u001B[0;34m(cls, instance, gateway, conf)\u001B[0m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    431\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_gateway:\n\u001B[0;32m--> 432\u001B[0m         SparkContext\u001B[38;5;241m.\u001B[39m_gateway \u001B[38;5;241m=\u001B[39m gateway \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mlaunch_gateway\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    433\u001B[0m         SparkContext\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;241m=\u001B[39m SparkContext\u001B[38;5;241m.\u001B[39m_gateway\u001B[38;5;241m.\u001B[39mjvm\n\u001B[1;32m    435\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m instance:\n",
      "File \u001B[0;32m~/apps/miniconda/envs/pyspark_env/lib/python3.9/site-packages/pyspark/java_gateway.py:106\u001B[0m, in \u001B[0;36mlaunch_gateway\u001B[0;34m(conf, popen_kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(conn_info_file):\n\u001B[0;32m--> 106\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJava gateway process exited before sending its port number\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(conn_info_file, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m info:\n\u001B[1;32m    109\u001B[0m     gateway_port \u001B[38;5;241m=\u001B[39m read_int(info)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "                    .master(\"local[*]\")\\\n",
    "                    .appName(\"test\")\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca10724-ca72-4539-9e01-17d40c1f6b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-05 18:49:21--  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.155.128.187, 18.155.128.46, 18.155.128.222, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.155.128.187|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 302633211 (289M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘fhvhv_tripdata_2021-02.parquet’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 288.61M  45.2MB/s    in 6.4s    \n",
      "\n",
      "2023-08-05 18:49:28 (45.1 MB/s) - ‘fhvhv_tripdata_2021-02.parquet’ saved [302633211/302633211]\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2a9a9b-2a4d-4341-ab35-ac3693fce91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d fhvhv_tripdata_2021-01.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4174590-2268-4148-b968-c6fa97fd3e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hvfhs_license_num,dispatching_base_num,pickup_datetime,dropoff_datetime,PULocationID,DOLocationID,SR_Flag\n",
      "HV0003,B02682,2021-01-01 00:33:44,2021-01-01 00:49:07,230,166,\n",
      "HV0003,B02682,2021-01-01 00:55:19,2021-01-01 01:18:21,152,167,\n",
      "HV0003,B02764,2021-01-01 00:23:56,2021-01-01 00:38:05,233,142,\n",
      "HV0003,B02764,2021-01-01 00:42:51,2021-01-01 00:45:50,142,143,\n",
      "HV0003,B02764,2021-01-01 00:48:14,2021-01-01 01:08:42,143,78,\n",
      "HV0005,B02510,2021-01-01 00:06:59,2021-01-01 00:43:01,88,42,\n",
      "HV0005,B02510,2021-01-01 00:50:00,2021-01-01 01:04:57,42,151,\n",
      "HV0003,B02764,2021-01-01 00:14:30,2021-01-01 00:50:27,71,226,\n",
      "HV0003,B02875,2021-01-01 00:22:54,2021-01-01 00:30:20,112,255,\n"
     ]
    }
   ],
   "source": [
    "!head fhvhv_tripdata_2021-01.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f421555-3970-4e8a-b039-e1547994dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option('header','true')\\\n",
    "    .csv('data/fhvhv_tripdata_2021-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "465ffe06-a9b3-4d34-a23b-24c531665ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', StringType(), True), StructField('DOLocationID', StringType(), True), StructField('SR_Flag', StringType(), True)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e15559ad-9003-4b24-8da3-0e2cd0c36eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', StringType(), True), StructField('DOLocationID', StringType(), True), StructField('SR_Flag', StringType(), True)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a546825-7743-483e-b5bd-8fab415a0c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969773 data/fhvhv_tripdata_2021-02.parquet\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/fhvhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6824f77-c03a-49cb-af3c-2a1f300658ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l fhvhv_tripdata_2021-01.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ae49dcc-1380-49b2-b8b4-0fe27e571cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-05 19:03:04--  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.155.128.6, 18.155.128.222, 18.155.128.187, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.155.128.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 558874878 (533M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘fhvhv_tripdata_2020-02.parquet’\n",
      "\n",
      "fhvhv_tripdata_2020 100%[===================>] 532.98M  44.3MB/s    in 12s     \n",
      "\n",
      "2023-08-05 19:03:17 (44.5 MB/s) - ‘fhvhv_tripdata_2020-02.parquet’ saved [558874878/558874878]\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc7f832-fab7-4370-ba45-41c67fcb16bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14a704b4-5666-47d0-ba28-e037222437db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema=types.StructType([\n",
    "\t\ttypes.StructField('hvfhs_license_num', types.StringType(), True), \n",
    "\t\ttypes.StructField('dispatching_base_num', types.StringType(), True), \n",
    "\t\ttypes.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "\t\ttypes.StructField('dropoff_datetime', types.TimestampType(), True), \n",
    "\t\ttypes.StructField('PULocationID', types.IntegerType(), True), \n",
    "\t\ttypes.StructField('DOLocationID', types.IntegerType(), True), \n",
    "\t\ttypes.StructField('SR_Flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90abb8ec-8bc0-4a14-99fe-47de3ed24856",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .option('header','true')\\\n",
    "    .schema(schema)\\\n",
    "    .csv('data/fhvhv_tripdata_2021-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9f5828f-0453-4399-8bed-27ff73e978b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 33, 44), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 49, 7), PULocationID=230, DOLocationID=166, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 55, 19), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 18, 21), PULocationID=152, DOLocationID=167, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 23, 56), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 38, 5), PULocationID=233, DOLocationID=142, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 42, 51), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 45, 50), PULocationID=142, DOLocationID=143, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 48, 14), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 8, 42), PULocationID=143, DOLocationID=78, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 6, 59), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 43, 1), PULocationID=88, DOLocationID=42, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 50), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 4, 57), PULocationID=42, DOLocationID=151, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 14, 30), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 50, 27), PULocationID=71, DOLocationID=226, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02875', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 22, 54), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 30, 20), PULocationID=112, DOLocationID=255, SR_Flag=None)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e213665-bc24-459d-8970-361074f0e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89478a2f-f6a4-40be-99e1-1b610e9311df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/07 08:02:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/08/07 08:02:43 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/08/07 08:02:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/08/07 08:02:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/08/07 08:02:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/08/07 08:02:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv_tripdata/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3321338-2a01-4eab-a12c-2fccd466fce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmdir: failed to remove 'fhvhv_tripdata/2021/01/': Directory not empty\n"
     ]
    }
   ],
   "source": [
    "!rmdir fhvhv_tripdata/2021/01/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52ab341a-308e-49d7-b43c-87e01224da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  fhvhv_tripdata  manip_spark_1.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03afd3-5a8a-4969-b445-7d88424a460c",
   "metadata": {},
   "source": [
    "Now we are going to read the parquet file reartitionned in 24 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84d8ba49-d86c-4171-a843-61fea8748a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= spark.read.parquet('fhvhv_tripdata/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fe521e9-1799-448f-b734-5e23b4e5ee3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e628113e-56eb-4701-b640-8beb099778f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-02 20:27:02|2021-01-02 20:35:57|         249|         107|\n",
      "|2021-01-02 16:38:39|2021-01-02 16:49:56|         225|          62|\n",
      "|2021-01-03 15:53:25|2021-01-03 15:57:36|         123|         123|\n",
      "|2021-01-02 18:27:36|2021-01-02 19:07:42|         132|         265|\n",
      "|2021-01-01 01:26:50|2021-01-01 01:40:27|         255|          79|\n",
      "|2021-01-03 11:47:58|2021-01-03 11:55:33|         243|         119|\n",
      "|2021-01-01 10:32:57|2021-01-01 10:52:13|         181|         125|\n",
      "|2021-01-01 03:21:44|2021-01-01 04:04:56|          92|          42|\n",
      "|2021-01-04 14:32:22|2021-01-04 14:47:36|         144|          68|\n",
      "|2021-01-05 10:12:17|2021-01-05 10:31:43|          17|         181|\n",
      "|2021-01-02 19:48:31|2021-01-02 19:56:13|         228|         227|\n",
      "|2021-01-04 20:56:43|2021-01-04 21:15:38|          61|          85|\n",
      "|2021-01-04 20:52:04|2021-01-04 21:01:28|         170|         113|\n",
      "|2021-01-04 18:21:44|2021-01-04 18:30:20|          36|         198|\n",
      "|2021-01-01 17:17:03|2021-01-01 17:22:39|         209|         232|\n",
      "|2021-01-02 23:00:27|2021-01-02 23:08:03|         167|         167|\n",
      "|2021-01-02 16:56:14|2021-01-02 17:13:41|          33|          89|\n",
      "|2021-01-04 07:32:17|2021-01-04 07:45:37|         188|          35|\n",
      "|2021-01-05 05:29:51|2021-01-05 05:44:48|         244|         143|\n",
      "|2021-01-02 11:25:29|2021-01-02 11:37:52|          13|         234|\n",
      "+-------------------+-------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "df.select('pickup_datetime','dropoff_datetime','PULocationID','DOLocationID')\\\n",
    "    .filter(df.hvfhs_license_num =='HV0003')\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0c0c07e-b86c-452c-9e3e-da8068bba576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1dca10a-43d9-4cdd-90ce-7ff9b2e31e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0 :\n",
    "        return f'a/{num:03x}'\n",
    "    else :\n",
    "         return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d662de0-f7ed-4ac2-9b79-6f8b65974d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s/00\\x05'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 5\n",
    "f's/{num:03c}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9534959d-30fd-4df8-aa9d-c7a92b3425b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a/b43'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crazy_stuff('B02883')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b6d3bff-640a-4fcd-93be-fc38c4d1a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "crazystuff_udf =  F.udf(crazy_stuff,returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b486d2cb-b17d-450c-afa4-3d1f92e164d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+------------+-------+\n",
      "|pickup_date|dropoff_date|PULocationID|DOLocationID|base_id|\n",
      "+-----------+------------+------------+------------+-------+\n",
      "| 2021-01-02|  2021-01-02|         249|         107|  a/b43|\n",
      "| 2021-01-02|  2021-01-02|         225|          62|  s/b13|\n",
      "| 2021-01-03|  2021-01-03|         123|         123|  s/acd|\n",
      "| 2021-01-02|  2021-01-02|         143|          24|  e/9ce|\n",
      "| 2021-01-02|  2021-01-02|         132|         265|  e/b47|\n",
      "| 2021-01-02|  2021-01-02|          48|         163|  e/9ce|\n",
      "| 2021-01-01|  2021-01-01|         255|          79|  s/b13|\n",
      "| 2021-01-03|  2021-01-03|         243|         119|  e/b3e|\n",
      "| 2021-01-03|  2021-01-03|         244|         244|  e/9ce|\n",
      "| 2021-01-01|  2021-01-01|         181|         125|  e/b3b|\n",
      "| 2021-01-01|  2021-01-01|          92|          42|  s/acd|\n",
      "| 2021-01-04|  2021-01-04|         144|          68|  e/acc|\n",
      "| 2021-01-05|  2021-01-05|          17|         181|  e/b38|\n",
      "| 2021-01-02|  2021-01-02|         228|         227|  a/a7a|\n",
      "| 2021-01-04|  2021-01-04|          61|          85|  e/b3c|\n",
      "| 2021-01-04|  2021-01-04|         170|         113|  e/acc|\n",
      "| 2021-01-01|  2021-01-01|          91|          39|  e/9ce|\n",
      "| 2021-01-04|  2021-01-04|          36|         198|  s/b44|\n",
      "| 2021-01-01|  2021-01-01|         209|         232|  e/acc|\n",
      "| 2021-01-01|  2021-01-01|         132|          48|  e/9ce|\n",
      "+-----------+------------+------------+------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df\\\n",
    "    .withColumn('pickup_date',F.to_date(df.pickup_datetime))\\\n",
    "    .withColumn('dropoff_date',F.to_date(df.dropoff_datetime))\\\n",
    "    .withColumn('base_id',crazystuff_udf(df.dispatching_base_num))\\\n",
    "    .select('pickup_date','dropoff_date','PULocationID','DOLocationID','base_id')\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9192420-310c-4469-a92a-fca669f556c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
